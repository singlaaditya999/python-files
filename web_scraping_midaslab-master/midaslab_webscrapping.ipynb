{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup using Python\n",
    "#### Website : [Midas Labs](http://midas.iiitd.edu.in)\n",
    "This project crawls the html content of midas labs and creates 2 files- \n",
    "- imglinks.txt : It contains the urls of images in all the pages present in the navigation bar \n",
    "- textdata.txt : It contains the text data of articles, paragraphs, and headings of the webpages present in the navigation bar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class WebScrap():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def getHTML(self, url):\n",
    "        return requests.get(url).text\n",
    "\n",
    "    def makeSoup(self, html_content):\n",
    "        return BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "    #This function will return all the links of a webpage except the links of particular focussing an element (starting with #)\n",
    "    def getAllLinks(self, html_soup):\n",
    "        all_links = html_soup.find_all('a')\n",
    "        valid_links=[]\n",
    "\n",
    "        for link_content in all_links:\n",
    "            link_a = link_content['href']\n",
    "            #Validating the link\n",
    "            if len(link_a)>0 and (link_a[0]) is not '#':\n",
    "                if '#' in link_a:\n",
    "                    char_idx = link_a.find('#')\n",
    "                    new_link = link_a[:char_idx]\n",
    "                else:\n",
    "                    new_link = link_a\n",
    "\n",
    "                if new_link not in valid_links:\n",
    "                    valid_links.append(new_link)\n",
    "        return valid_links\n",
    "\n",
    "    def getAllLinksText(self, html_soup):\n",
    "        all_links = html_soup.find_all('a')\n",
    "        valid_links_text=[]\n",
    "\n",
    "        for link_content in all_links:\n",
    "            link_a = link_content['href']\n",
    "            #Validating the link\n",
    "            if len(link_a)>0 and (link_a[0]) is not '#':\n",
    "                if '#' in link_a:\n",
    "                    char_idx = link_a.find('#')\n",
    "                    new_link = link_a[:char_idx]\n",
    "                else:\n",
    "                    new_link = link_a\n",
    "\n",
    "                if new_link not in valid_links_text:\n",
    "                    valid_links_text.append(link_content.text)\n",
    "        return valid_links_text\n",
    "\n",
    "    #This function will get the urls of all the images in a page\n",
    "    def getImgLinks(self, html_soup):\n",
    "        img_links = html_soup.find_all('img')\n",
    "        img_links = map(lambda x: x['src'], img_links)\n",
    "        return list(img_links)\n",
    "\n",
    "    #This function will get the urls of all the images in a page\n",
    "    def getContent(self, elements):\n",
    "        return list(map(lambda x: x.text, elements))\n",
    "\n",
    "    #This function will get the text data in a page\n",
    "    def getTextData(self, html_soup):\n",
    "        text_data=[]\n",
    "        text_data += self.getContent(html_soup.find_all('p'))\n",
    "        text_data += self.getContent(html_soup.find_all('a'))\n",
    "        text_data += self.getContent(html_soup.find_all('div',class_='bigtitle'))\n",
    "        text_data += self.getContent(html_soup.find_all('h1'))\n",
    "        text_data += self.getContent(html_soup.find_all('h2'))\n",
    "        text_data += self.getContent(html_soup.find_all('h3'))\n",
    "        text_data += self.getContent(html_soup.find_all('h4'))\n",
    "        text_data += self.getContent(html_soup.find_all('h5'))\n",
    "        return text_data\n",
    "\n",
    "baseURL='http://midas.iiitd.edu.in'\n",
    "midaslab = WebScrap()\n",
    "web_content = midaslab.getHTML(baseURL)\t\t\n",
    "soup = midaslab.makeSoup(web_content) \n",
    "links = midaslab.getAllLinks(soup)\n",
    "links_text = midaslab.getAllLinksText(soup)\n",
    "#Navigation pages URL\n",
    "nav_pages_links = links[:8]\n",
    "nav_pages_links_text = links_text[:8]\n",
    "#Iterating over all the navigation links to find out the urls of images and writing it to the file\n",
    "pageno=1\n",
    "with open('imglinks.txt', 'w') as f:\n",
    "    for linkno in range(0,len(nav_pages_links)):\n",
    "        nav_url=nav_pages_links[linkno]\n",
    "        nav_text=nav_pages_links_text[linkno]\n",
    "        web_content_navpage = midaslab.getHTML(baseURL+nav_url)\n",
    "        soup_navpage = midaslab.makeSoup(web_content_navpage)\n",
    "        imglinks = midaslab.getImgLinks(soup_navpage)\n",
    "        f.write('Page No-{}, Name - {}\\n'.format(pageno,nav_text))\n",
    "        f.write('Page Link- {}{}\\n'.format(baseURL,nav_url))\n",
    "        f.write('Image Links--\\n')\n",
    "        for img_link in imglinks:\n",
    "            f.write(\"{}{}\\n\".format(baseURL,img_link))\n",
    "        f.write('----------------------------------\\n'.format(pageno))\n",
    "        pageno += 1\n",
    "\n",
    "#Iterating over all the navigation links to find out the text data and writing it to the file\n",
    "pageno=1\n",
    "with open('textdata.txt', 'w') as f:\n",
    "    for linkno in range(0,len(nav_pages_links)):\n",
    "        nav_url=nav_pages_links[linkno]\n",
    "        nav_text=nav_pages_links_text[linkno]\n",
    "        web_content_navpage = midaslab.getHTML(baseURL+nav_url)\n",
    "        soup_navpage = midaslab.makeSoup(web_content_navpage)\n",
    "        textdata = midaslab.getTextData(soup_navpage)\n",
    "        f.write('Page No-{}, Name - {}\\n'.format(pageno,nav_text))\n",
    "        f.write('Page Link- {}{}\\n'.format(baseURL,nav_url))\n",
    "        f.write('Text Data--\\n')\n",
    "        for textdata_row in textdata:\n",
    "            f.write(\"{}\\n\".format(textdata_row))\n",
    "        f.write('----------------------------------\\n\\n'.format(pageno))\n",
    "        pageno += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page No-1, Name - \n",
      "\n",
      "\n",
      "Page Link- http://midas.iiitd.edu.in/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/banner/banner.jpeg\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/banner/group_1.jpeg\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/banner/group.jpeg\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/banner/group_2.jpeg\n",
      "----------------------------------\n",
      "Page No-2, Name - Research\n",
      "Page Link- http://midas.iiitd.edu.in/projects/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "http://midas.iiitd.edu.in/assets/images/projects/multimodal-social-media.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/projects/lipper.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/projects/ai-healtcare.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/projects/eventbuilder.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/projects/code-switched-language.jpg\n",
      "----------------------------------\n",
      "Page No-3, Name - Team\n",
      "Page Link- http://midas.iiitd.edu.in/team/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "http://midas.iiitd.edu.in/assets/images/team/rajiv.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/shivangi.png\n",
      "http://midas.iiitd.edu.in/assets/images/team/hitkul.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/vaibhav.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/himani.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/prateekrawat.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/pallavi.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/himanshuaggarwal.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/shagun.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/midas_abhishek.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/Akash_pic.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/rajat-bansal.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/Dhruva-Sahrawat.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/vedant.JPG\n",
      "http://midas.iiitd.edu.in/assets/images/team/osaid.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/harsh.png\n",
      "http://midas.iiitd.edu.in/assets/images/team/mohits.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/RamaKrishna.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/mehak.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/hemant.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/imageKush.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/puneet.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/pic.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/Nilay.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/nupur-baghel.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/f2.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/shashwat-aggarwal.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/mansi-agarwal.png\n",
      "http://midas.iiitd.edu.in/assets/images/team/Raghav_pic.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/apoorv_image.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/Namrata-Mukhija.JPG\n",
      "http://midas.iiitd.edu.in/assets/images/team/anmol-chugh.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/arnav-arora.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/hritwik-dutta.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/karm.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/IMG_9517.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/team/yaman.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/simra.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/sarthak.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/salik.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/rohit.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/rajat.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/meghna.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/laiba.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/hitesh.jpeg\n",
      "http://midas.iiitd.edu.in/assets/images/team/anjali.jpeg\n",
      "----------------------------------\n",
      "Page No-4, Name - Papers\n",
      "Page Link- http://midas.iiitd.edu.in/papers/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/ThematicSimilarity.png\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/WWW-aspect.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/Geometry-based-Localization.gif\n",
      "http://midas.iiitd.edu.in/assets/images/papers/default-paper.svg\n",
      "http://midas.iiitd.edu.in/assets/images/papers/Virtualization-in-Wireless-Sensor-Networks.gif\n",
      "----------------------------------\n",
      "Page No-5, Name - Blog\n",
      "Page Link- http://midas.iiitd.edu.in/blog/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "http://midas.iiitd.edu.in/assets/images/blog/myl-1.jpg\n",
      "http://midas.iiitd.edu.in/assets/images/blog/myl-2.jpg\n",
      "http://midas.iiitd.edu.inhttps://drive.google.com/file/d/1-CAxz-_l6hG_AHbv3azHr9g5D2xdIfZz/view?usp=sharing\n",
      "----------------------------------\n",
      "Page No-6, Name - Openings\n",
      "Page Link- http://midas.iiitd.edu.in/openings/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "----------------------------------\n",
      "Page No-7, Name - News\n",
      "Page Link- http://midas.iiitd.edu.in/news/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "http://midas.iiitd.edu.in/assets/images/news/default-news.png\n",
      "----------------------------------\n",
      "Page No-8, Name - Events\n",
      "Page Link- http://midas.iiitd.edu.in/events/\n",
      "Image Links--\n",
      "http://midas.iiitd.edu.in/assets/themes/lab/images/logo/LOGO.png\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('imglinks.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page No-1, Name - \n",
      "\n",
      "\n",
      "Page Link- http://midas.iiitd.edu.in/\n",
      "Text Data--\n",
      "MIDAS is a group of researchers at IIIT-Delhi who study, analyze, and build different multimedia systems for society leveraging multimodal information. MIDAS stands for Multimodal Digital Media Analysis Lab and it is founded by Dr. Rajiv Ratn Shah. Dr. Shah is assistant professor in the department of Computer Science and Engineering (jointly appointed with the department of Human Centered Design) at IIIT-Delhi. Our work at MIDAS includes Machine Learning, Multimedia Content Processing, Natural Language Processing, Image Processing, Multimodal Computing, Data Science, Social Media Computing, and the Internet of Things. We believe in multidisciplinary collabrative research and work closely with eminent researchers from National University of Singapore (NUS), National Institute of Informatics (NII), Nanyang Technological University (NTU), Bloomberg, Arkana Lab, etc.\n",
      "\n",
      "We are on Facebook and Twitter now. www.facebook.com/midasIIITD and www.twitter.com/midasIIITD\n",
      "Congratulations Vaishali for getting placed in Qualcomm.\n",
      "A paper titled, “Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed”, got accepted in the Brave New Idea track of ACM Multimedia 2018 (approx 8% acceptance rate). Congratulation to authors: Yaman Kumar, Mayank Aggarwal, Pratham Nawal, Shin’ichi Satoh, Rajiv Ratn Shah, Roger Zimmerman.\n",
      "MIDAS founder and collaborators, Rajiv Ratn Shah, Yifang Yin, and Roger Zimmermann published a full paper titled, “Learning and Fusing Multimodal Deep Features for Acoustic Scene Categorization”, in the ACM Multimedia 2018, a premier conference for multimedia research.\n",
      "\n",
      "\n",
      "\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "News\n",
      "\n",
      "\t\t\t\t\tWe are on FB and Twiter now\n",
      "\t\t\t\t\t\n",
      "www.facebook.com/midasIIITD\n",
      "www.twitter.com/midasIIITD\n",
      "Rajiv\n",
      "\n",
      "\t\t\t\t\tVaishali got placed\n",
      "\t\t\t\t\t\n",
      "Rajiv\n",
      "\n",
      "\t\t\t\t\tPaper accepted at ACMMM2018\n",
      "\t\t\t\t\t\n",
      "Yaman Kumar\n",
      "Mayank Aggarwal\n",
      "Pratham Nawal\n",
      "Shin’ichi Satoh\n",
      "Rajiv Ratn Shah\n",
      "Roger Zimmerman\n",
      "Rajiv\n",
      "\n",
      "\t\t\t\t\tPaper accepted at ACMMM2018\n",
      "\t\t\t\t\t\n",
      "Rajiv Ratn Shah\n",
      "Yifang Yin\n",
      "Roger Zimmermann\n",
      "Rajiv\n",
      "Posts\n",
      "\n",
      "\t\t\t\t\tMind Your Language\n",
      "\t\t\t\t\t\n",
      "Raghav\n",
      "\n",
      "\t\t\t\t\tKiki Challenge Dataset Release\n",
      "\t\t\t\t\t\n",
      "Raghav\n",
      "Papers\n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t\tDid you offend me? Classification of Offensive Tweets in Hinglish Language\n",
      "\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\tGet IT Scored using AutoSAS - An Automated System for Scoring Short Answers\n",
      "\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\tIdentification of Emergency Blood Donation Request on Twitter\n",
      "\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\tExploring and Learning Suicidal Ideation Connotations in Social Media with DL\n",
      "\t\t\t\t\t\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "----------------------------------\n",
      "\n",
      "Page No-2, Name - Research\n",
      "Page Link- http://midas.iiitd.edu.in/projects/\n",
      "Text Data--\n",
      "\n",
      "In recent years, a huge amount of user-generated content (UGC) online (e.g., text, images, and videos) is accumulated on the web. UGC available on different platforms helps social media companies in sensing feedback, opinion, and interests of users, and provide services accordingly. However, due to the vast amount of data and inherent noise in social media content, often it is difficult to extract useful information from a single modality. Thus, it is essential to leverage information from multiple modalities to reduce noise from social media content. We leverage both multimedia content and contextual information to provide solutions to several important problems such as fake news detection, trolling detection, hate-speech detection, popularity predictions of photos, soundtrack recommendations for videos, and event summarization. At MIDAS@IIITD, we focus on building efficient fusion mechanisms using deep neural networks techniques which can help social media companies to provide a better service to their users. Our recent papers on multimodal social media analysis are published in top-tier conferences such as ACM Multimedia, WWW, NAACL, etc.\n",
      "\n",
      "Speechreading broadly involves looking, perceiving, and interpreting spoken symbols. It has a wide range of multimedia applications, such as surveillance, Internet telephony, and as an aid to a person with hearing impairments. However, most of the work in speechreading has been limited to text generation from silent videos. Recently, research has ventured into generating (audio) speech from silent video sequences but there have been no developments in using multiple cameras for speech generation. To this end, this project encompasses the boundaries of multimedia research by putting forth a model which leverages silent video feeds from multiple cameras recording the same subject to generate intelligent speech for a speaker. Initial results confirm the usefulness of exploiting multiple views in building an efficient speech reading and reconstruction system. It further shows the optimal placement of cameras which would lead to the maximum intelligibility of speech. At MIDAS@IIITD, we plan to leverage the proposed system in various innovative applications and focus on its potential prodigious impact in not just security arena but in many other multimedia analytics problems. Our recent paper on speech reconstruction from silent videos is published in ACM Multimedia, a premier Multimedia conference.\n",
      "\n",
      "In recent years, advances in artificial intelligence techniques haveyielded immense success in computer vision, natural language processing, and speech processing. Healthcare is also one of the areas which got much benefited through this. Mining social media messages for health and drug-related information has received significant interest in pharmacovigilance research. For instance, an analysis of social media text (e.g., tweets, posts, and comments) using natural language processing and machine learning techniques helps in finding the adverse drug reactions, suicidal ideation, depression detection, medical information extraction, etc. Moreover, computer vision and machine learning techniques help the automatic detection of different disease from tissue images. For instance, it has shown immense success in the detection of cancer, diabetes, kidney failure, etc. Furthermore, speech processing in conjunction with artificial intelligence has shown great success in the treatment of people. Moreover, artificial intelligence helps in building systems for people with different abilities. At MIDAS@IIITD, we focus on several such interesting research problems (e.g., kidney glomeruli classification, automatic kidney fibrosis assessment, adverse drug reactions, and suicidal ideation ) leveraging deep learning techniques. Our recent papers in this area are published in top-tier conferences and journals such as IEEE Intelligent Systems, NAACL, etc.\n",
      "\n",
      "With the advent of smartphones and auto-uploaders, user-generated content (e.g., tweets, photos, and videos) uploads on social media have become more numerous and asynchronous. Thus, it is difficult and time taking for users to manually search (detect) interesting events. It requires for social media companies to automatically detect events and subsequently recommend them to their users. An automatic event detection is also very useful in an efficient search and retrieval of user-generated content. Furthermore, since the number of users and events on event-based social networks (EBSN) is increasing rapidly, it is not feasible for users to manually find the personalized events of their interest. We would like to further explore events on EBSN such as Meetup for different multimedia analytics projects such as recommending events, groups, and friends to users. At MIDAS@IIITD, we would like to use Deep Neural Network (DNN) technologies due to their immense success to address these interesting problems. Our recent papers on event detection and summarization are published in top-tier conferences and journals such as Knowledge-Based Systems, ACM Multimedia, ACM ICMR, etc.\n",
      "\n",
      "The exponential rise of social media websites like Twitter, Facebook and Reddit in linguistically diverse geographical regions has led to hybridization of popular native languages with English in an effort to ease communication. For instance, Hinglish is formed of the words spoken in Hindi language but written in Roman script instead of the Devanagari script. It is a pronunciation based bi-lingual language that has no fixed grammar rules. Therefore, it is difficult to derive any useful information from such code-switched languages. Therefore, it necessitates social media companies to build models that can extract useful information from such languages. This will be useful in a number of applications such as detecting offensive languages, understanding feedback, opinions, and sentiments of users towards some product, news, events, policies, etc. At MIDAS@IIITD, we focus on building deep learning models which can extract useful information and automatically perform efficient classifications from code-switched languages such as Hinglish. For instance, our recent paper on detecting offensive language in Hinglish tweets is published in ACL, a premier NLP conference.\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "----------------------------------\n",
      "\n",
      "Page No-3, Name - Team\n",
      "Page Link- http://midas.iiitd.edu.in/team/\n",
      "Text Data--\n",
      "Assistant Professor\n",
      "PhD Scholar\n",
      "PhD Scholar\n",
      "M.Tech Student\n",
      "M.Tech Student\n",
      "M.Tech Student\n",
      "M.Tech Student\n",
      "M.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student\n",
      "B.Tech Student, Rustamji Institute of Technology, BSF Academy.\n",
      "B.Tech Student, BML Munjal University\n",
      "B.Tech Student, IIIT Bhubaneswar\n",
      "B. Tech, IIIT Vadodara\n",
      "Research Assistant, IIIT-Delhi\n",
      "B.Tech Student, NSIT\n",
      "Research Assistant, NSIT\n",
      "B.Tech Student, NSIT-Delhi\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, USICT\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, DTU\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, DTU\n",
      "B.Tech Student, NSIT\n",
      "Software Developer, Adobe Systems\n",
      "Research Assistants, IIIT-Delhi\n",
      "B.Tech Student, NSIT\n",
      "Developer, Gramener\n",
      "Software Developer, Tower Research Capital\n",
      "Developer, Adobe\n",
      "B.Tech Student, DTU\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, MAIT\n",
      "Research Assistants, IIIT-Delhi\n",
      "B.Tech Student, DTU\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, DTU\n",
      "Research Fellow, National University of Singapore, Singapore\n",
      "Assistant Professor, National Institute of Informatics, Japan\n",
      "Assistant Professor, IIIT-Delhi\n",
      "Nephropathologist, Arkana Laboratories, USA\n",
      "Professor, National Institute of Informatics, Japan\n",
      "Associate Professor, National University of Singapore, Singapore\n",
      "Associate Professor, IIIT-Delhi\n",
      "Lecturer, Nottingham Trent University, U.K.\n",
      "Lecturer, University of Technology Sydney, Australia\n",
      "Associate Professor, Singapore Management University, Singapore\n",
      "Research Scientist, Bloomberg LP, USA\n",
      "Assistant Professor, IIIT-Delhi\n",
      "Research Scientist, Nanyang Technological University, Singapore\n",
      "SDE, Microsoft\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, NSIT\n",
      "Part Time Researcher, WalmartLabs\n",
      "B.Tech Student, IIIT-Delhi\n",
      "B.Tech Student, IIIT-Delhi\n",
      "Research Associate, IIIT Bhubaneswar\n",
      "M.Tech 2018, Microsoft\n",
      "M.Tech 2018, Intel\n",
      "M.Tech Student, IIIT-Delhi\n",
      "M.Tech Student, IIIT-Delhi\n",
      "B.Tech Student, IIIT-Delhi\n",
      "B.Tech Student, MSIT\n",
      "B.Tech Student, NSIT\n",
      "B.Tech, GGSIPU\n",
      "B.Tech Student, NSIT\n",
      "B.Tech Student, DTU\n",
      "B.Tech Student, DTU\n",
      "B.Tech Student, DTU\n",
      "B.Tech 2018, Western Digital\n",
      "B.Tech Student, IIT Mandi\n",
      "B.Tech Student, JIIT\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "\n",
      "\n",
      "\n",
      "Rajiv Ratn Shah\n",
      "\n",
      "\n",
      "\n",
      "Shivangi Singhal\n",
      "\n",
      "\n",
      "\n",
      "Hitkul\n",
      "\n",
      "\n",
      "\n",
      "Vaibhav Varshney\n",
      "\n",
      "\n",
      "\n",
      "Himani Sharma\n",
      "\n",
      "\n",
      "\n",
      "Prateek Rawat\n",
      "\n",
      "\n",
      "\n",
      "Pallavi S. Rawat\n",
      "\n",
      "\n",
      "\n",
      "Himanshu Aggarwal\n",
      "\n",
      "\n",
      "\n",
      "Shagun Uppal\n",
      "\n",
      "\n",
      "\n",
      "Abhishek Gupta\n",
      "\n",
      "\n",
      "\n",
      "Akash Gautam\n",
      "\n",
      "\n",
      "\n",
      "Rajat Bansal\n",
      "\n",
      "\n",
      "\n",
      "Dhruva Sahrawat\n",
      "\n",
      "\n",
      "\n",
      "Vedant Bhatia\n",
      "\n",
      "\n",
      "\n",
      "Osaid Rehman Nasir\n",
      "\n",
      "\n",
      "\n",
      "Harsh Shrivastava\n",
      "\n",
      "\n",
      "\n",
      "Mohit Sharma\n",
      "\n",
      "\n",
      "\n",
      "P V N S Rama Krishna\n",
      "\n",
      "\n",
      "\n",
      "Mehak Piplani\n",
      "\n",
      "\n",
      "\n",
      "Hemant Yadav\n",
      "\n",
      "\n",
      "\n",
      "Kush Misra\n",
      "\n",
      "\n",
      "\n",
      "Puneet Mathur\n",
      "\n",
      "\n",
      "\n",
      "Astitwa Saxena\n",
      "\n",
      "\n",
      "\n",
      "Nilay Shrivastava\n",
      "\n",
      "\n",
      "\n",
      "Nupur Baghel\n",
      "\n",
      "\n",
      "\n",
      "Rajat Maheshwari\n",
      "\n",
      "\n",
      "\n",
      "Shashwat Aggarwal\n",
      "\n",
      "\n",
      "\n",
      "Mansi Agarwal\n",
      "\n",
      "\n",
      "\n",
      "Raghav Kapoor\n",
      "\n",
      "\n",
      "\n",
      "Apoorv Bhardwaj\n",
      "\n",
      "\n",
      "\n",
      "Namrata Mukhija\n",
      "\n",
      "\n",
      "\n",
      "Anmol Chugh\n",
      "\n",
      "\n",
      "\n",
      "Arnav Arora\n",
      "\n",
      "\n",
      "\n",
      "Hritwik Dutta\n",
      "\n",
      "\n",
      "\n",
      "Karmanya Aggarwal\n",
      "\n",
      "\n",
      "\n",
      "Ramit Sawhney\n",
      "\n",
      "\n",
      "\n",
      "Yaman\n",
      "\n",
      "\n",
      "\n",
      "SIMRA SHAHID\n",
      "\n",
      "\n",
      "\n",
      "Sarthak Anand\n",
      "\n",
      "\n",
      "\n",
      "Mohammad Salik\n",
      "\n",
      "\n",
      "\n",
      "Rohit Jain\n",
      "\n",
      "\n",
      "\n",
      "Rajat\n",
      "\n",
      "\n",
      "\n",
      "Meghna P Ayyar\n",
      "\n",
      "\n",
      "\n",
      "Laiba Mehnaz\n",
      "\n",
      "\n",
      "\n",
      "Hitesh Nankani\n",
      "\n",
      "\n",
      "\n",
      "Anjali Bhavan\n",
      "Dr. Yifang Yin\n",
      "Dr. Yi Yu\n",
      "Dr. Tanmoy Chakraborty\n",
      "Dr. Shree Gopal Sharma\n",
      "Dr. Shin’ichi Satoh\n",
      "Dr. Roger Zimmermann\n",
      "Dr. Ponnurangam Kumaraguru\n",
      "Dr. Omprakash Kaiwartya\n",
      "Dr. Mukesh Prasad\n",
      "Dr. Jing Jiang\n",
      "Dr. Debanjan Mahata\n",
      "Dr. A.V. Subramanyam\n",
      "Dr. Soujanya Poria\n",
      "Shivli Agrawal \n",
      "Yukti Girdhar\n",
      "Paavini Nanda\n",
      "Raghav Mehta\n",
      "Varnit Jain\n",
      "Karan Dabas\n",
      "Aditya Kumar Pathak\n",
      "Sanket Jain\n",
      "Ashutosh Pandey\n",
      "Vaishali Dabral\n",
      "Tushar Jain\n",
      "Shubham Thakral\n",
      "Sahil Chopra\n",
      "Pratham Nawal\n",
      "Prakhar Srivastava\n",
      "Mayank Aggarwal\n",
      "Himanshu\n",
      "Ayush Gupta\n",
      "Akash Kumar\n",
      "Agniv Sharma\n",
      "Abhigyan Khaund\n",
      "Aarya Patel\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "Faculty\n",
      "Graduate Students\n",
      "Post-Graduate Students\n",
      "Undergraduate Students\n",
      "Interns/ Research Assistants\n",
      "Collaborator\n",
      "Alumni\n",
      "----------------------------------\n",
      "\n",
      "Page No-4, Name - Papers\n",
      "Page Link- http://midas.iiitd.edu.in/papers/\n",
      "Text Data--\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "\n",
      "\n",
      "\n",
      "Did you offend me? Classification of Offensive Tweets in Hinglish Language\n",
      "\n",
      "\n",
      "\n",
      "Get IT Scored using AutoSAS - An Automated System for Scoring Short Answers\n",
      "\n",
      "\n",
      "\n",
      "Identification of Emergency Blood Donation Request on Twitter\n",
      "\n",
      "\n",
      "\n",
      "Exploring and Learning Suicidal Ideation Connotations in Social Media with DL\n",
      "\n",
      "\n",
      "\n",
      "Neural Machine Translation for English-Tamil\n",
      "\n",
      "\n",
      "\n",
      "Mind Your Language: Abuse and Offense Detection for Code-Switched Languages\n",
      "\n",
      "\n",
      "\n",
      "DeepLip: Speaker Independent Speech Synthesis using Multi-View Lipreading\n",
      "\n",
      "\n",
      "\n",
      "Lipper: Synthesizing Thy Speech using Multi-View Lipreading\n",
      "\n",
      "\n",
      "\n",
      "Exploring Classification of Histological Disease Bio-markers from Renal Biopsy Images\n",
      "\n",
      "\n",
      "\n",
      "Kiki Kills: Identifying Dangerous Challenge Videos from Social Media\n",
      "\n",
      "\n",
      "\n",
      "Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed\n",
      "\n",
      "\n",
      "\n",
      "Learning and Fusing Multimodal Deep Features for Acoustic Scene Categorization\n",
      "\n",
      "\n",
      "\n",
      "Detecting Offensive Tweets in Hindi-English Code-Switched Language\n",
      "\n",
      "\n",
      "\n",
      "Key2Vec: Automatic Ranked Keyphrase Extraction from Scientific Articles using Phrase Embeddings\n",
      "\n",
      "\n",
      "\n",
      "#phramacovigilance - Exploring Deep Learning Techniques for Identifying Mentions of Medication Intake from Twitter\n",
      "\n",
      "\n",
      "\n",
      "Aspect-Based Financial Sentiment Analysis using Deep Learning\n",
      "\n",
      "\n",
      "\n",
      "Theme-weighted Ranking of Keywords from Text Documents using Phrase Embeddings\n",
      "\n",
      "\n",
      "\n",
      "A Multimodal Approach to Predict Social Media Popularity\n",
      "\n",
      "\n",
      "\n",
      "Did you take the #pill? - Detecting Personal Intake of Medicine from Twitter\n",
      "\n",
      "\n",
      "\n",
      "Feature-based Map Matching for Low-Sampling-Rate GPS Trajectories\n",
      "\n",
      "\n",
      "\n",
      "Geometry-based Localization for GPS Outage in Vehicular Cyber Physical Systems\n",
      "\n",
      "\n",
      "\n",
      "FastShrinkage: Perceptually-aware Retargeting Toward Mobile Platforms\n",
      "\n",
      "\n",
      "\n",
      "Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "----------------------------------\n",
      "\n",
      "Page No-5, Name - Blog\n",
      "Page Link- http://midas.iiitd.edu.in/blog/\n",
      "Text Data--\n",
      "This blog is about our research project where we studied abuse and offense detection in the code switched pair of Hindi and English(i.e., Hinglish) under the expert guidance of Dr. Rajiv Ratn Shah, Dr. Roger Zimmermann, and Dr. Ponnurangam Kumaraguru.\n",
      "As we write this blog, we remember our journey as research interns at MIDAS Lab. We started this project as our college project in August ’18 when this idea was like a small seed which was sown by our friend Yaman Kumar who is experienced in this field. He introduced us with the highly intellectual professors at MIDAS Lab, who not only gave us a direction but also galvanized us each day into transforming this small idea into a full-fledged research project. As we started working, we became cognizant of the fact that it this a vital issue in today’s world and must be addressed. From what we discovered in our journey; we would like to give everyone a glimpse of it - A small idea that turned into a publication in one of the most prestigious conference of Artificial Intelligence - AAAI’19 at Honolulu, Hawaii, USA, as part of the student abstract and poster track.\n",
      "In the Indian Subcontinent the number of Internet users has been continuously rising with the penetration of internet among the masses.It is being estimated that the number of internet users in India will cross 700 million by 2021.With about 53% of the users using Hinglish as the medium of communication on social media in India, the need of the the hour is to have some system to detect hate speech,offensive and abusive posts on social media.\n",
      "Although there are many previous works which deal with Hindi and English hate speech (the top two languages in India), but very few on the code-switched version (Hinglish) of the two (Mathur et al. 2018). This is partially due to the following reasons:\n",
      "Our work primarily consists of these steps: Preprocessing of the dataset, training of word embeddings,training of the classifier model and then using that on HEOT dataset. Preprocessing involves transliteration using Indic-transliteration python library and translation using Xlit-crowd conversion dictionary which was manually added with common Hinglish words and some profane words. This was followed by training of Glove(Pennington, Socher, and Manning 2014) and Twitter word2vec(Godin et al. 2015) embeddings on both the Davidson and HEOT dataset.Finally a ternary classification model was used using LSTM to classify these tweets into three categories(offensive, abusive and  benign).\n",
      "\n",
      "\n",
      "As shown in the above figure the model was initially trained on the dataset provided by Davidson and then re-trained on the HEOT dataset so as to benefit from the transfer of learned features in the last stage.\n",
      "\n",
      "\n",
      "We have produced “state of the art” results for english.Our model trained on Glove embeddings gives the best results on HEOT dataset. For comparison purposes we also calculate the results of our model on the Davidson dataset.\n",
      "In future we look to extend the work in the following ways:\n",
      "Use dependency based word embeddings and compare them to the normal word embeddings.\n",
      "Work on a model to classify images and videos(also having hindi text) into three categories offensive, abusive and  benign.\n",
      "Detect and report facebook users and pages based on their recent posts.\n",
      "We feel immensely proud to be the part of this extremely enjoyable journey where we not only learnt just theoretically but also implemented those concepts to real life applications to witness the great impact that technology and artificial intelligence brings to life. We feel honoured and grateful on being able to contribute our skills and simultaneously learn each day from our guides and professors at MIDAS Lab who inspired us throughout the project. This has been a totally satisfying and rewarding experience and would wish to work with the team in future as well to use technology for a better tomorrow. Also, we would like to thank Puneet Mathur for sharing the HEOT dataset and inspiring us through his work in the following paper “Mathur, P.; Shah, R.; Sawhney, R.; and Mahata, D. 2018. Detecting offensive tweets in hindi-english code-switched language. In Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media, 18–26.”\n",
      "Above all, we thank Almighty God for giving us this opportunity, being with us and guiding us in all situations and making our way through each and every problem.\n",
      "Here is a link to a short video for better understanding of the project - https://drive.google.com/open?id=1rpEcsv03B1yifjLftllK3Hep-Ecyzew2\n",
      "One of the most famous online social media challenge these days is the Kiki challenge. Also known as “In My Feelings Challenge” or “Do The Shiggy”, it originated when a comedian Shiggy released a video, dancing on the road to the tunes of this song by Drake. Since then people have considered it to be a challenge in which they need to get down of a moving car, and dance alongside the traffic risking their lives and getting their video captured.\n",
      "There is no country which has been left untouched when it comes to this. It originated in Canada and spread over the world including United States, Mexico, United Kingdom, India, South Africa, Costa Rica, Egypt, Argentina and so on. People are sharing thousands of tweets commonly involving their videos on a daily basis on social platforms like Twitter and Facebook.\n",
      "While it is good to dance and burn some calories, but when it comes to the road it is not such a brilliant idea. There has been many reported incidents where people have been hit by speedy vehicles, fallen off the car and collided head-start with electric poles. It possesses a serious risk to life if not taken with precautions and may even lead to death.\n",
      "Realising the importance and implications that this challenge has on the life of so many people, MIDAS decided to build a system which can detect the danger in a given video. The exact methodology followed by us was -\n",
      "We started with collecting tweets for the last 15 days using the Tweepy API. Next, we scanned through the data to find out what were the top 20 most commonly used hashtags during the July-August duration using their frequency of occurrence.\n",
      "Results of this analysis can be found here - Distribution of Hashtags in Twitter data\n",
      "Tweet Collection: The common hashtags discovered in the previous step were used as keywords for further searching of tweets for the complete duration of late June to September. Data from hashtags such as #mumbai police and #egypt police which had comparatively smaller frequency were collected separately.\n",
      "Video Collection: After we had a good set of tweets, we used the URLs provided as a parameter inside tweets to download corresponding videos.\n",
      "Annotation: Two annotators worked through the complete list of videos categorising them as either safe or dangerous. Removal of retweeted videos as well as irrelevant videos which seemed to not relate was simultaneously done.\n",
      "Cross annotation parameter was also calculated by labelling 400 videos for each of the annotators to ensure there was consistency. This test was successful and we obtained a high value (0.95) of Cohen’s Kappa.\n",
      "We built a video classification model with VGG16 as the base model. This was appended with a subtle combination of flatten, fully connected dense layers, max pooling layers and dropout layers.\n",
      "The model works by taking as input a batch of data containing captured frames of the video we want to classify. The output produced is the probabilities of video between safe and dangerous. Thus we classify the category of the video after rounding the probabilities to the nearest possible values.\n",
      "\n",
      "We used model checkpointing to store the weights of the best model. Further, to determine the consistency of our model we evaluated it on the test set. An accuracy of 87 percent was obtained, along with a precision of 0.96, and recall score of 0.9.\n",
      "Although the current model is fair enough to generate good results, it can surely be improved to account for time analysis using recurrent neural network models. \n",
      "We also plan to create a hybrid model which can take into account both the textual and visual data in a tweet and generate results more accurately.\n",
      "Nupur Baghel, Yaman Kumar, Paavini Nanda, Rajiv Ratn Shah, Debanjan Mahata and Roger Zimmermann \n",
      "All of us are members of the MIDAS community.\n",
      "To help on improving research in this domain we are hereby releasing the dataset which contains more than 2.3k videos of the KIKI challenge collected from Twitter.\n",
      "For the time being the dataset is avalable on request. Anyone intrested can send us a request via E-mail stating there purpose of use (We did some work for you, just click here). We will respond within 7 days.\n",
      "Please refre our dataset as below\n",
      "Nupur Baghel, Yaman Kumar, Paavini Nanda, Rajiv Ratn Shah, Debanjan Mahata and Roger Zimmermann : Kiki Kills: Identifying Dangerous Challenge Videos from Social Media (2018).\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "Mind Your Language\n",
      "Raghav\n",
      "https://drive.google.com/open?id=1rpEcsv03B1yifjLftllK3Hep-Ecyzew2\n",
      "Kiki Challenge Dataset Release\n",
      "Raghav\n",
      "Distribution of Hashtags in Twitter data\n",
      "here\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "Why Hinglish(code switched pair of Hindi and English) ?\n",
      "Has it been done before?\n",
      "Our contribution!\n",
      "Results\n",
      "Applications\n",
      "Future Work\n",
      "Introduction\n",
      "What’s wrong !!?\n",
      "Our contributions\n",
      "Future Work\n",
      "About Us:\n",
      "KIKI Datasets Download\n",
      "What is this challenge about?\n",
      "How popular is the challenge ?\n",
      "1. Analysing the common hashtags used\n",
      "2. Creating a dataset from social platforms\n",
      "3. Building a model for detecting dangerous incidents\n",
      "4. Evaluation of models to judge their consistency\n",
      "The following video provides a complete summary:\n",
      "The authors involved for this project are:\n",
      "----------------------------------\n",
      "\n",
      "Page No-6, Name - Openings\n",
      "Page Link- http://midas.iiitd.edu.in/openings/\n",
      "Text Data--\n",
      "We look for motivated students and interns in our group who are interested to work in the following\n",
      "    areas:\n",
      "Interested students can email their latest CV at midas@iiitd.ac.in,\n",
      "    subject line of email should follow the following format: Application for PhD/intern/RA/BTP etc.\n",
      "We are also open to industry collaboration to solve interesting research problems which can facilitate\n",
      "    society. If you are interested to collaborate with MIDAS then feel free to call us at +91-11-26907495 or\n",
      "    email us at midas@iiitd.ac.in\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "Research Intern \n",
      "Research Assistant \n",
      "Research Assistant \n",
      "midas@iiitd.ac.in\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "Research Intern \n",
      "Research Assistant \n",
      "Research Assistant \n",
      "----------------------------------\n",
      "\n",
      "Page No-7, Name - News\n",
      "Page Link- http://midas.iiitd.edu.in/news/\n",
      "Text Data--\n",
      "We are on Facebook and Twitter now. www.facebook.com/midasIIITD and www.twitter.com/midasIIITD\n",
      "Congratulations Vaishali for getting placed in Qualcomm.\n",
      "A paper titled, “Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed”, got accepted in the Brave New Idea track of ACM Multimedia 2018 (approx 8% acceptance rate). Congratulation to authors: Yaman Kumar, Mayank Aggarwal, Pratham Nawal, Shin’ichi Satoh, Rajiv Ratn Shah, Roger Zimmerman.\n",
      "MIDAS founder and collaborators, Rajiv Ratn Shah, Yifang Yin, and Roger Zimmermann published a full paper titled, “Learning and Fusing Multimodal Deep Features for Acoustic Scene Categorization”, in the ACM Multimedia 2018, a premier conference for multimedia research.\n",
      "MIDAS students, Hitkul, Shivangi Singhal, and Himanshu Aggarwal, got selected for six months fully funded internship at National Institute of Informatics, Tokyo, Japan.\n",
      "MIDAS collaborator, Dr Debanjan Mahata, is appointed as an adjunct faculty at IIIT-Delhi.\n",
      "MIDAS student, Shivangi Singhal, got selected for the ACM India Grad Cohort 2018 which will be held in IIIT Bombay.\n",
      "MIDAS intern, Hitkul, enrolled for PhD under the supervision of Prof Rajiv Ratn Shah and Prof PK at IIITD.\n",
      "We made our paper titled, “ #phramacovigilance - Exploring Deep Learning Techniques for Identifying Mentions of Medication Intake from Twitter”, online on Arxiv to the research community.\n",
      "MIDAS founder, Dr. Rajiv Ratn Shah, and collaborator, Dr. Debanjan Mahata, got their research paper, titled “Did you take the pill? – Detecting Personal Intake of Medicine from Twitter”, accepted in the special chapter of IEEE Intelligent Systems on Affective Computing and Sentiment Analysis.\n",
      "MIDAS founder, Dr. Rajiv Ratn Shah, got selected for the Heidelberg Laureate Forum fellowship 2018 which will be held in Heidelberg, Germany.\n",
      "Prof Rada Mihalcea from University of Michigan has delivered a keynote on “Multimodal Sensing of Human Behavior” in the MR2AMC workshop organized by MIDAS.\n",
      "MIDAS founder, Dr. Rajiv Ratn Shah, organized MR2AMC workshop in conjunction with IEEE MIPR conference at Miami, Florida, USA.\n",
      "Professor Shin’ichi Satoh and Prof Henri Angelino from the National Institute of Informatics (NII), Japan visited MIDAS@IIITD  to sign MOU between NII and IIIT-Delhi to establish research collaboration between two institutes. MIDAS founder, Prof Rajiv Ratn Shah, is the contact person at IIIT-Delhi for this research collaboration.\n",
      "MIDAS students, Hitkul and Shivangi Singhal, got their research paper, titled “Aspect-Based Financial Sentiment Analysis using Deep Learning”, accepted in WWW 2018.\n",
      "MIDAS founder, Dr. Rajiv Ratn Shah, and collaborator, Dr. Debanjan Mahata, got their research paper, titled “Key2Vec: Automatic Ranked Keyphrase Extraction from Scientific Articles Using Phrase Embeddings”, accepted in NAACL 2018.\n",
      "Our paper titled, “A Multimodal Approach to Predict Social Media Popularity “, got accepted in the MR2AMC workshop 2018\n",
      "Our paper titled, “A Multimodal Approach to Predict Social Media Popularity “, got accepted in the MR2AMC workshop 2018\n",
      "MIDAS workshop proposal, MR2AMC, is accepted in the IEEE MIPR conference which will be held at Miami, Florida, USA.\n",
      "Shivangi Singhal joined as the first PhD student of the MIDAS lab under the supervision of Prof Rajiv Ratn Shah and Prof Tanmoy Chakraborty.\n",
      "Hitkul joined as the first intern of the MIDAS lab under the supervision of Prof Rajiv Ratn Shah.\n",
      "Prof Rajiv Ratn Shah founded the MIDAS lab.\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "rajiv\n",
      "\n",
      "www.facebook.com/midasIIITD\n",
      "www.twitter.com/midasIIITD\n",
      "rajiv\n",
      "\n",
      "rajiv\n",
      "\n",
      "Yaman Kumar\n",
      "Mayank Aggarwal\n",
      "Pratham Nawal\n",
      "Shin’ichi Satoh\n",
      "Rajiv Ratn Shah\n",
      "Roger Zimmerman\n",
      "rajiv\n",
      "\n",
      "Rajiv Ratn Shah\n",
      "Yifang Yin\n",
      "Roger Zimmermann\n",
      "rajiv\n",
      "\n",
      "Hitkul\n",
      "Shivangi Singhal\n",
      "National Institute of Informatics\n",
      "rajiv\n",
      "\n",
      "Dr Debanjan Mahata\n",
      "IIIT-Delhi\n",
      "rajiv\n",
      "\n",
      "Shivangi Singhal\n",
      "ACM India Grad Cohort 2018\n",
      "rajiv\n",
      "\n",
      "Hitkul\n",
      "Prof Rajiv Ratn Shah\n",
      "Prof PK\n",
      "rajiv\n",
      "\n",
      "rajiv\n",
      "\n",
      "Dr. Rajiv Ratn Shah\n",
      "Dr. Debanjan Mahata\n",
      "rajiv\n",
      "\n",
      "Dr. Rajiv Ratn Shah\n",
      "rajiv\n",
      "\n",
      "Prof Rada Mihalcea\n",
      "rajiv\n",
      "\n",
      "Dr. Rajiv Ratn Shah\n",
      "IEEE MIPR conference\n",
      "rajiv\n",
      "\n",
      "Professor Shin’ichi Satoh\n",
      "National Institute of Informatics (NII), Japan\n",
      "IIIT-Delhi\n",
      "Prof Rajiv Ratn Shah\n",
      "rajiv\n",
      "\n",
      "Hitkul\n",
      "Shivangi Singhal\n",
      "WWW 2018\n",
      "rajiv\n",
      "\n",
      "Dr. Rajiv Ratn Shah\n",
      "Dr. Debanjan Mahata\n",
      "NAACL 2018\n",
      "rajiv\n",
      "\n",
      "rajiv\n",
      "\n",
      "rajiv\n",
      "\n",
      "IEEE MIPR conference\n",
      "rajiv\n",
      "\n",
      "Shivangi Singhal\n",
      "Prof Rajiv Ratn Shah\n",
      "Prof Tanmoy Chakraborty\n",
      "rajiv\n",
      "\n",
      "Hitkul\n",
      "Prof Rajiv Ratn Shah\n",
      "rajiv\n",
      "\n",
      "Prof Rajiv Ratn Shah\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "----------------------------------\n",
      "\n",
      "Page No-8, Name - Events\n",
      "Page Link- http://midas.iiitd.edu.in/events/\n",
      "Text Data--\n",
      "MR2AMC is a series of workshops on Multimodal Representation, Retrieval, and Analysis of Multimedia Content organized by the MIDAS lab in IIIT-Delhi. MIDAS stands for Multimodal Digital Media Analysis Lab and it consists a group of researchers who study, analyze, and build different multimedia systems for society leveraging multimodal information. The first iteration of the workshop held in conjunction with the IEEE MIPR conference. The second iteration of the workshop will be held in conjunction with the 20th IEEE International Conference on Multimedia in Taichung, Taiwan. This year’s workshop theme is social media. Thus, MR2AMC aims to provide an international forum for researchers in the field of multimedia data processing, analysis, search, mining, and management leveraging multimodal information in social media. This workshop will provide a forum to researchers and practitioners from both academia and industry for original research contributions and practical system design, implementation, and applications of multimodal multimedia information processing, mining, representation, management, and retrieval. MR2AMC 2018 invites research papers in the area of multimodal multimedia content analysis, search and retrieval, semantic computing, and affective computing. Accepted papers of MR2AMC 2018 will be published as part of the workshop proceedings in the IEEE Digital Library. Extended versions of the accepted workshop papers will be invited for publication in Springer Cognitive Computation and IEEE Computational Intelligence Magazine.\n",
      "\n",
      "\n",
      "\n",
      "MIDAS@IIITD\n",
      "Research\n",
      "Team\n",
      "Papers\n",
      "Blog\n",
      "Openings\n",
      "\n",
      "              More \n",
      "\n",
      "News\n",
      "Events\n",
      "MR2AMC\n",
      "Springer Cognitive Computation\n",
      "IEEE Computational Intelligence Magazine\n",
      "\n",
      "Indraprastha Institute of Information Technology, Delhi\n",
      "About\n",
      "Contact\n",
      "----------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('textdata.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
